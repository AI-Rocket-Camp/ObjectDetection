{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:45:09.674285Z",
     "start_time": "2020-01-02T10:45:09.671164Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 旧版本的Pytorch中，Variable是对Tensor的一个封装；在Pytorch大于v0.4的版本后，Varible和Tensor合并了，意味着Tensor可以像旧版本的Variable那样运行，当然新版本中Variable封装仍旧可以用，但是对Varieble操作返回的将是一个Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:45:27.231423Z",
     "start_time": "2020-01-02T10:45:27.224669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor ->variable\n",
    "x = Variable(t.ones(4,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:45:52.583451Z",
     "start_time": "2020-01-02T10:45:52.578525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable->tensor\n",
    "y = x.data\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对于那些不是任何函数(Function)的输出，由用户创建的节点称为叶子节点，叶子节点的grad_fn为None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:09.213194Z",
     "start_time": "2020-01-02T10:32:09.202652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "tensor([0.3741, 0.2563, 0.1793], requires_grad=True)\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,requires_grad=True)\n",
    "b = torch.rand(3,requires_grad=True)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a.grad)  #为None\n",
    "a.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:27.017281Z",
     "start_time": "2020-01-02T10:32:27.012468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*b\n",
    "c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:30.807337Z",
     "start_time": "2020-01-02T10:32:30.804005Z"
    }
   },
   "outputs": [],
   "source": [
    "a.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:35.030863Z",
     "start_time": "2020-01-02T10:32:35.026021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x121d57b38>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:38.872721Z",
     "start_time": "2020-01-02T10:32:38.866038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8097, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d=c.sum()\n",
    "print(d)\n",
    "d.backward()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只有requires_grad为True，且从其他节点调用函数backward()，则不为None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:32:49.119513Z",
     "start_time": "2020-01-02T10:32:49.115778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3741, 0.2563, 0.1793])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 首先Tensor是默认不需要求导的，即requires_grad默认为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:11:46.246635Z",
     "start_time": "2020-01-02T10:11:46.241235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果某一个节点requires_grad被设置为True，那么所有依赖它的节点requires_grad都为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:17:47.510591Z",
     "start_time": "2020-01-02T10:17:47.498441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    " \n",
    "a = t.ones(3)\n",
    "b = t.ones(3,requires_grad=True)\n",
    "b.requires_grad\n",
    "#输出：True\n",
    "c = a + b\n",
    "c.requires_grad\n",
    "#输出：True.虽然c没有指定需要求导，然是c依赖于b，而b需要求导，所以c.requires_grad=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
